from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import logging
import re
import os

os.makedirs("/tmp/cache", exist_ok=True)
os.environ["TRANSFORMERS_CACHE"] = "/tmp/cache"
os.environ["HF_HOME"] = "/tmp"

app = Flask(__name__)
CORS(app)

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Activer une gestion plus lÃ©gÃ¨re de PyTorch
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:32"

# Variable globale pour le modÃ¨le (chargement paresseux)
qwen_pipeline = None

def load_model_if_needed():
    """Charge le modÃ¨le seulement quand nÃ©cessaire"""
    global qwen_pipeline
    if qwen_pipeline is None:
        try:
            from transformers import pipeline
            logger.info("ğŸ”„ Chargement du modÃ¨le Qwen1.5B-Chat...")

            qwen_pipeline = pipeline(
                "text-generation",
                model="Qwen/Qwen1.5B-Chat",
                max_new_tokens=30,
                truncation=True,
                pad_token_id=50256,
                eos_token_id=50256,
                repetition_penalty=1.2,
                do_sample=True,
                temperature=0.7,
                top_k=50,
                top_p=0.95,
                torch_dtype="auto",
                device_map="auto"
            )
            logger.info("âœ… ModÃ¨le Qwen1.5B-Chat chargÃ© avec succÃ¨s")
            return True
        except Exception as e:
            logger.error(f"âŒ Ã‰chec du chargement du modÃ¨le : {str(e)}")
            qwen_pipeline = "error"  # Marquer comme erreur
            return False
    return qwen_pipeline != "error"


# RÃ©ponses personnalisÃ©es (fallback)
CUSTOM_RESPONSES = {
    "bonjour": "Bonjour ! Comment puis-je vous aider aujourd'hui ?",
    "salut": "Salut ! Que puis-je faire pour vous ?",
    "comment Ã§a va": "Je vais bien, merci ! Et vous ?",
    "au revoir": "Au revoir ! Passez une excellente journÃ©e !",
    "merci": "De rien, je suis lÃ  pour vous aider !",
    "hello": "Hello! How can I help you today?",
    "hi": "Hi there! What can I do for you?",
    "qui t'a conÃ§u": "RaphaÃ«l NiamÃ© (+225) 05 06 53 15 22",
    "qui t'a concu": "RaphaÃ«l NiamÃ© (+225) 05 06 53 15 22",
    "qui t'a fait": "RaphaÃ«l NiamÃ© (+225) 05 06 53 15 22",
    "qui est messy charles": "C'est le pÃ¨re de Manou et Messy",
    "bonsoir": "Bonsoir ! Comment puis-je vous aider ce soir ?",
    "bien": "OK. Que puis-je faire pour vous ?",
    "trÃ¨s bien": "OK. Que puis-je faire pour vous ?",
    "je vais bien et toi": "TrÃ¨s bien. Comment puis-je vous aider ?",
    "comment vas-tu": "Je vais bien, merci ! Et vous ?",
    "comment allez-vous": "Je vais bien, merci ! Et vous ?",
    "comment t'appelles-tu": "Je suis un assistant virtuel sans nom propre. Tu peux m'appeler simplement 'Assistant'. Comment puis-je t'aider aujourd'hui ?",
    "qui es-tu": "Je suis un assistant virtuel sans nom propre. Tu peux m'appeler simplement 'Assistant'. Comment puis-je t'aider aujourd'hui ?",
    "quel est ton nom": "Je suis un assistant virtuel sans nom propre. Tu peux m'appeler simplement 'Assistant'. Comment puis-je t'aider aujourd'hui ?",
    "tu t'appelles comment": "Je suis un assistant virtuel sans nom propre. Tu peux m'appeler simplement 'Assistant'. Comment puis-je t'aider aujourd'hui ?",
    "qui est raphael niame": "C'est un dÃ©veloppeur freelance d'applications web, mobiles et bureaux.",
    "comment contacter raphael niame": "RaphaÃ«l NiamÃ©: (+225) 05 06 53 15 22",
    "email": "niame225@gmail.com",
    "oulai": "c'est le pÃ¨re de Tchounatchou",
    "soma": "c'est un cÃ©lÃ¨bre agent immobilier",
    "orÃ© Roland": "C'est un grand homme d'affaires. Il est ivoirien"
}

def get_custom_response(message):
    """Cherche une rÃ©ponse personnalisÃ©e avec correspondance de mots-clÃ©s multiples"""
    if not message:
        return None

    message_lower = message.lower().strip()

    # Nettoyer le message : supprimer la ponctuation et sÃ©parer en mots
    clean_message = re.sub(r'[^\w\s]', ' ', message_lower)
    message_words = set(clean_message.split())

    # Parcourir toutes les rÃ©ponses personnalisÃ©es
    for key, response in CUSTOM_RESPONSES.items():
        # Nettoyer la clÃ© de la mÃªme faÃ§on
        clean_key = re.sub(r'[^\w\s]', ' ', key.lower())
        key_words = clean_key.split()

        # VÃ©rifier si tous les mots de la clÃ© sont dans le message
        if key_words and all(word in message_words for word in key_words):
            logger.info(f"Correspondance trouvÃ©e: '{key}' -> '{message}'")
            return response

    # Si aucune correspondance exacte, essayer une correspondance partielle
    for key, response in CUSTOM_RESPONSES.items():
        key_lower = key.lower()
        if key_lower in message_lower or message_lower in key_lower:
            logger.info(f"Correspondance partielle: '{key}' -> '{message}'")
            return response

    return None


def get_local_model_response(message):
    """Utilise un modÃ¨le local (Qwen1.5B) pour gÃ©nÃ©rer une rÃ©ponse"""
    try:
        if not load_model_if_needed():
            return "âš ï¸ Le modÃ¨le IA est temporairement indisponible."

        logger.info(f"Envoi au modÃ¨le local: {message}")

        prompt = f"User: {message}\nAssistant:"
        response = qwen_pipeline(prompt)

        if response and len(response) > 0:
            generated_text = response[0]['generated_text'].replace(prompt, '').strip()

            if generated_text:
                return generated_text.split('\n')[0][:200]  # Limite Ã  200 caractÃ¨res

        return "Je n'ai pas rÃ©ussi Ã  comprendre votre question."

    except Exception as e:
        logger.error(f"Erreur modÃ¨le local: {str(e)}")
        return "Erreur lors de la gÃ©nÃ©ration de la rÃ©ponse."


def get_bot_response(message):
    """Fonction principale pour obtenir une rÃ©ponse"""
    if not message or len(message.strip()) == 0:
        return "Veuillez saisir un message."

    if len(message) > 200:
        return "Message trop long (max 200 caractÃ¨res)."

    # 1. RÃ©ponses personnalisÃ©es d'abord (plus rapide et Ã©conome)
    custom_response = get_custom_response(message)
    if custom_response:
        logger.info(f"RÃ©ponse personnalisÃ©e pour: {message}")
        return custom_response

    # 2. ModÃ¨le local IA seulement si nÃ©cessaire
    return get_local_model_response(message)


@app.route('/')
def home():
    """Page d'accueil basique"""
    return jsonify({
        "status": "Chatbot prÃªt âœ…",
        "description": "Envoyez une requÃªte POST Ã  /chat pour commencer.",
        "developer": "RaphaÃ«l NiamÃ© (+225) 05 06 53 15 22",
        "routes": ["/chat", "/ask", "/health", "/test"]
    })


@app.route('/chat', methods=['POST'])
def chat():
    """Route principale pour le chat (JSON)"""
    try:
        logger.info("RequÃªte reÃ§ue sur /chat")

        if not request.is_json:
            return jsonify({'error': 'Content-Type doit Ãªtre application/json'}), 400

        data = request.get_json()
        if not data:
            return jsonify({'error': 'DonnÃ©es JSON manquantes'}), 400

        user_message = data.get('message', '').strip()
        logger.info(f"Message reÃ§u: '{user_message}'")

        if not user_message:
            return jsonify({'response': 'Veuillez saisir un message.'})

        bot_response = get_bot_response(user_message)
        logger.info(f"RÃ©ponse envoyÃ©e: '{bot_response}'")

        return jsonify({'response': bot_response})

    except Exception as e:
        logger.error(f"Erreur dans /chat: {str(e)}")
        return jsonify({'error': f'Erreur serveur: {str(e)}'}), 500


@app.route('/ask', methods=['POST'])
def ask():
    """Route pour compatibilitÃ© (FormData et JSON)"""
    try:
        logger.info("RequÃªte reÃ§ue sur /ask")

        if request.is_json:
            data = request.get_json()
            user_message = data.get('message', '').strip()
        else:
            user_message = request.form.get('message', '').strip()

        logger.info(f"Message /ask: '{user_message}'")

        if not user_message:
            return jsonify({'response': 'Veuillez saisir un message.'})

        bot_response = get_bot_response(user_message)
        return jsonify({'response': bot_response})

    except Exception as e:
        logger.error(f"Erreur /ask: {str(e)}")
        return jsonify({'error': f'Erreur: {str(e)}'}), 500


@app.route('/health')
def health():
    """VÃ©rification santÃ©"""
    model_status = "Non chargÃ©" if qwen_pipeline is None else ("Erreur" if qwen_pipeline == "error" else "Actif âœ…")
    return jsonify({
        'status': 'OK âœ…',
        'message': 'Flask fonctionne',
        'model_status': model_status,
        'developer': 'RaphaÃ«l NiamÃ© (+225) 05 06 53 15 22'
    })


@app.route('/test')
def test():
    """Test de l'API"""
    test_response = get_bot_response("bonjour")
    return jsonify({
        'test_message': 'bonjour',
        'response': test_response,
        'status': 'OK âœ…'
    })


# Gestion d'erreurs
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Route non trouvÃ©e'}), 404

@app.errorhandler(500)
def server_error(error):
    return jsonify({'error': 'Erreur serveur interne'}), 500


if __name__ == '__main__':
    logger.info("ğŸš€ DÃ©marrage du chatbot optimisÃ© pour Render")

    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)